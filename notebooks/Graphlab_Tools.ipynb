{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LOAD DATA WITH SPARK (25% of the directory 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'1.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.wholeTextFiles(\"test_bed_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def parser(x):\n",
    "    return BeautifulSoup(x, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Train CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Finished parsing file /Users/ricardo/Documents/GuillermoGaps/spark-1.4.1/Kaggle_competition/train.csv\n",
      "PROGRESS: Parsing completed. Parsed 100 lines in 0.107852 secs.\n",
      "------------------------------------------------------\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "PROGRESS: Finished parsing file /Users/ricardo/Documents/GuillermoGaps/spark-1.4.1/Kaggle_competition/train.csv\n",
      "PROGRESS: Parsing completed. Parsed 101107 lines in 0.072736 secs.\n"
     ]
    }
   ],
   "source": [
    "train = gl.SFrame('train.csv')\n",
    "t = list(train['file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Mapped the data using Beautifulsoup to get the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapped_data = data.map(lambda x: [x[0].split(\"/\")[-1], parser(x[1]).get_text(), \"train\" if x[0].split(\"/\")[-1] in t else \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Keep only data from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapped_train_data = mapped_data.filter( lambda x: x[2]==\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/ricardo/Documents/GuillermoGaps/spark-1.4.1/python/lib/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/Users/ricardo/Documents/GuillermoGaps/spark-1.4.1/python/lib/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/Users/ricardo/Documents/GuillermoGaps/spark-1.4.1/python/lib/pyspark.zip/pyspark/serializers.py\", line 263, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/Users/ricardo/Documents/GuillermoGaps/spark-1.4.1/python/pyspark/rdd.py\", line 1273, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-4-acda85af58a0>\", line 1, in <lambda>\nNameError: global name 't' is not defined\n\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:138)\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.<init>(PythonRDD.scala:179)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:97)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:244)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:63)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:70)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1273)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1264)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1263)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1263)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1457)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1418)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-52aafa8d32b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmapped_train_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ricardo/Documents/GuillermoGaps/spark-1.4.1/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ricardo/Documents/GuillermoGaps/spark-1.4.1/python/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         port = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions,\n\u001b[0;32m--> 897\u001b[0;31m                                           allowLocal)\n\u001b[0m\u001b[1;32m    898\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ricardo/Documents/GuillermoGaps/spark-1.4.1/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[0;32m--> 538\u001b[0;31m                 self.target_id, self.name)\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ricardo/Documents/GuillermoGaps/spark-1.4.1/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    299\u001b[0m                     \u001b[0;34m'An error occurred while calling {0}{1}{2}.\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     format(target_id, '.', name), value)\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/ricardo/Documents/GuillermoGaps/spark-1.4.1/python/lib/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/Users/ricardo/Documents/GuillermoGaps/spark-1.4.1/python/lib/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/Users/ricardo/Documents/GuillermoGaps/spark-1.4.1/python/lib/pyspark.zip/pyspark/serializers.py\", line 263, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/Users/ricardo/Documents/GuillermoGaps/spark-1.4.1/python/pyspark/rdd.py\", line 1273, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-4-acda85af58a0>\", line 1, in <lambda>\nNameError: global name 't' is not defined\n\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:138)\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.<init>(PythonRDD.scala:179)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:97)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:244)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:63)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:70)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1273)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1264)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1263)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1263)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:730)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1457)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1418)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n"
     ]
    }
   ],
   "source": [
    "mapped_train_data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Import the RDD to SFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab as gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf = gl.SFrame.from_rdd(mapped_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ADD some features to the SFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sf['file'] = sf['X1'].apply(lambda x: x[0] )\n",
    "sf['html'] = sf['X1'].apply(lambda x: x[1].strip().replace(\"  \", \" \" ))\n",
    "sf['train'] = sf['X1'].apply(lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">X1</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">files</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">html</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1000188_raw_html.txt,<br>\\n\\n\\n\\n\\n   The impact ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1000188_raw_html.txt</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">The impact of shadow IT\\n<br>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1000662_raw_html.txt,<br>\\n\\n\\n\\n\\n\\n ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1000662_raw_html.txt</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">(function() { var b=windo<br>w,f=\"chrome\",g=\"tick\" ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1000860_raw_html.txt,<br>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1000860_raw_html.txt</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">J!NX : J!NX\\n<br>\\n\\n\\n\\n\\n\\n\\n  // ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1001544_raw_html.txt,<br>\\n\\n\\n\\n   Dudes With ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1001544_raw_html.txt</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Dudes With Beards With<br>Cats | Pictures of dudes ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1001670_raw_html.txt,<br>\\n\\n\\n\\n\\n\\n   Thanks ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1001670_raw_html.txt</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Thanks for Voting - R1\\n<br>\\n\\n  * {\\n\\tmargin: ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1002222_raw_html.txt,<br>\\n\\n\\n\\n   snopes.com: ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1002222_raw_html.txt</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">snopes.com: Professor<br>Indrek Wichman E-mail\\n ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1002774_raw_html.txt,<br>\\n\\n\\n\\n   Mick Jagger ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1002774_raw_html.txt</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Mick Jagger sends up<br>Monty Python before ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[100278_raw_html.txt,<br>\\n\\n\\n\\n   var ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">100278_raw_html.txt</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">var<br>ue_t0=window.ue_t0||+new ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1002978_raw_html.txt,<br>\\n\\n\\n\\n\\n\\n   var ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1002978_raw_html.txt</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">var _sf_startpt=(new<br>Date()).getTime()\\n ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1003068_raw_html.txt,<br>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1003068_raw_html.txt</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">How to Make Bacon Infused<br>Vodka - Betty Crocker ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">train</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[10 rows x 4 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tX1\tlist\n",
       "\tfiles\tstr\n",
       "\thtml\tstr\n",
       "\ttrain\tstr\n",
       "\n",
       "Rows: 10\n",
       "\n",
       "Data:\n",
       "+-------------------------------+----------------------+\n",
       "|               X1              |        files         |\n",
       "+-------------------------------+----------------------+\n",
       "| [1000188_raw_html.txt, \\n\\... | 1000188_raw_html.txt |\n",
       "| [1000662_raw_html.txt, \\n\\... | 1000662_raw_html.txt |\n",
       "| [1000860_raw_html.txt, \\n\\... | 1000860_raw_html.txt |\n",
       "| [1001544_raw_html.txt, \\n\\... | 1001544_raw_html.txt |\n",
       "| [1001670_raw_html.txt, \\n\\... | 1001670_raw_html.txt |\n",
       "| [1002222_raw_html.txt, \\n\\... | 1002222_raw_html.txt |\n",
       "| [1002774_raw_html.txt, \\n\\... | 1002774_raw_html.txt |\n",
       "| [100278_raw_html.txt, \\n\\n... | 100278_raw_html.txt  |\n",
       "| [1002978_raw_html.txt, \\n\\... | 1002978_raw_html.txt |\n",
       "| [1003068_raw_html.txt, \\n\\... | 1003068_raw_html.txt |\n",
       "+-------------------------------+----------------------+\n",
       "+-------------------------------+-------+\n",
       "|              html             | train |\n",
       "+-------------------------------+-------+\n",
       "| The impact of shadow IT\\n ... | train |\n",
       "| (function() { var b=window... | train |\n",
       "| J!NX : J!NX\\n \\n\\n\\n\\n\\n\\n... | train |\n",
       "| Dudes With Beards With Cat... | train |\n",
       "| Thanks for Voting - R1\\n \\... | train |\n",
       "| snopes.com: Professor Indr... | train |\n",
       "| Mick Jagger sends up Monty... | train |\n",
       "| var ue_t0=window.ue_t0||+n... | train |\n",
       "| var _sf_startpt=(new Date(... | train |\n",
       "| How to Make Bacon Infused ... | train |\n",
       "+-------------------------------+-------+\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Adding a few more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sf = sf.join(train,on=[\"file\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sf[\"length_html\"] = new_sf['html'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sf[\"bag_of_words\"] = gl.text_analytics.count_words(new_sf['html'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_var = gl.text_analytics.tf_idf(gl.text_analytics.count_words(new_sf['html']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_sf[\"tfidf\"] = my_var[\"docs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Removing stop words for tfidf, bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = gl.text_analytics.stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_sw(x):\n",
    "    cleaned = []\n",
    "    for element in x.split():\n",
    "        if element.lower() not in stop_words:\n",
    "            cleaned.append(element)\n",
    "    \n",
    "    return \" \".join(cleaned)\n",
    "\n",
    "new_sf['cleaned_html'] = new_sf['html'].apply(lambda x: remove_sw(x))\n",
    "new_sf['trigrams'] = gl.text_analytics.count_ngrams(new_sf['cleaned_html'], 3, \"word\")\n",
    "new_sf['bigrams'] = gl.text_analytics.count_ngrams(new_sf['cleaned_html'], 2, \"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sf['stop_tfidf'] = new_sf['tfidf'].dict_trim_by_keys(stop_words, exclude=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Counting Links, roughly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sf['https']= new_sf[\"html\"].apply(lambda x: x.count(\"https\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sf['http']= new_sf[\"html\"].apply(lambda x: x.count(\"http:\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Counting \"Sponsor content\" string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sf['sponsor_content'] = new_sf[\"html\"].apply(lambda x: x.lower().count(\"sponsor content\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training logistic regression with 'stop_tfidf','bigrams', 'trigrams','length_html' as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: Logistic regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 4285\n",
      "PROGRESS: Number of classes           : 2\n",
      "PROGRESS: Number of feature columns   : 4\n",
      "PROGRESS: Number of unpacked features : 9367344\n",
      "PROGRESS: Number of coefficients    : 9367345\n",
      "PROGRESS: Starting L-BFGS\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | 1         | 9        | 0.000006  | 26.483852    | 0.976429          | 0.905405            |\n",
      "PROGRESS: | 2         | 11       | 1.000000  | 35.466236    | 0.994166          | 0.891892            |\n",
      "PROGRESS: | 3         | 12       | 1.000000  | 40.244083    | 0.997666          | 0.891892            |\n",
      "PROGRESS: | 4         | 13       | 1.000000  | 44.246985    | 0.997433          | 0.891892            |\n",
      "PROGRESS: | 5         | 15       | 1.000000  | 53.510259    | 0.998366          | 0.891892            |\n",
      "PROGRESS: | 6         | 16       | 1.000000  | 57.828756    | 0.998366          | 0.891892            |\n",
      "PROGRESS: | 7         | 17       | 1.000000  | 61.938359    | 0.997900          | 0.891892            |\n",
      "PROGRESS: | 8         | 19       | 1.000000  | 68.435866    | 0.998600          | 0.891892            |\n",
      "PROGRESS: | 9         | 20       | 1.000000  | 74.242644    | 0.997433          | 0.891892            |\n",
      "PROGRESS: | 10        | 22       | 1.000000  | 83.574830    | 0.998600          | 0.891892            |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = new_sf.random_split(0.8, seed=1234)\n",
    "model_stop_tfidf = gl.logistic_classifier.create(train_data, target='sponsored', features = ['stop_tfidf','bigrams', 'trigrams','length_html'])\n",
    "#predictions = model.predict(test_data)\n",
    "results = model_stop_tfidf.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9051643192488263, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      1       |        0        |   98  |\n",
       " |      1       |        1        |   22  |\n",
       " |      0       |        0        |  942  |\n",
       " |      0       |        1        |   3   |\n",
       " +--------------+-----------------+-------+\n",
       " [4 rows x 3 columns]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Adding new features  'https','http','sponsor_content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: Logistic regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 4272\n",
      "PROGRESS: Number of classes           : 2\n",
      "PROGRESS: Number of feature columns   : 7\n",
      "PROGRESS: Number of unpacked features : 9389227\n",
      "PROGRESS: Number of coefficients    : 9389228\n",
      "PROGRESS: Starting L-BFGS\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | 1         | 9        | 0.000006  | 19.568847    | 0.977060          | 0.927660            |\n",
      "PROGRESS: | 2         | 11       | 1.000000  | 24.451804    | 0.993914          | 0.931915            |\n",
      "PROGRESS: | 3         | 12       | 1.000000  | 27.359136    | 0.997191          | 0.931915            |\n",
      "PROGRESS: | 4         | 13       | 1.000000  | 30.767318    | 0.998361          | 0.931915            |\n",
      "PROGRESS: | 5         | 14       | 1.000000  | 34.571952    | 0.999064          | 0.931915            |\n",
      "PROGRESS: | 6         | 15       | 1.000000  | 38.273200    | 0.998596          | 0.931915            |\n",
      "PROGRESS: | 7         | 16       | 1.000000  | 41.494421    | 0.999298          | 0.931915            |\n",
      "PROGRESS: | 8         | 17       | 1.000000  | 44.360605    | 0.999298          | 0.931915            |\n",
      "PROGRESS: | 9         | 18       | 1.000000  | 48.307320    | 0.999064          | 0.931915            |\n",
      "PROGRESS: | 10        | 19       | 1.000000  | 51.414418    | 0.999064          | 0.931915            |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = new_sf.random_split(0.8, seed=1234)\n",
    "model_stop_tfidf_2 = gl.logistic_classifier.create(train_data, target='sponsored', features = ['stop_tfidf','bigrams', 'trigrams','length_html','https','http','sponsor_content'])\n",
    "#predictions = model.predict(test_data)\n",
    "results_2 = model_stop_tfidf_2.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9042253521126761, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      1       |        0        |   95  |\n",
       " |      1       |        1        |   25  |\n",
       " |      0       |        0        |  938  |\n",
       " |      0       |        1        |   7   |\n",
       " +--------------+-----------------+-------+\n",
       " [4 rows x 3 columns]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Checking for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: Logistic regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 4269\n",
      "PROGRESS: Number of classes           : 2\n",
      "PROGRESS: Number of feature columns   : 4\n",
      "PROGRESS: Number of unpacked features : 9459148\n",
      "PROGRESS: Number of coefficients    : 9459149\n",
      "PROGRESS: Starting L-BFGS\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | Iteration | Passes   | Step size | Elapsed Time | Training-accuracy | Validation-accuracy |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | 1         | 8        | 0.000017  | 19.466184    | 0.965566          | 0.663866            |\n",
      "PROGRESS: | 2         | 10       | 1.000000  | 24.975398    | 0.995081          | 0.768908            |\n",
      "PROGRESS: | 3         | 11       | 1.000000  | 28.217244    | 0.997658          | 0.785714            |\n",
      "PROGRESS: | 4         | 12       | 1.000000  | 31.722840    | 0.997658          | 0.789916            |\n",
      "PROGRESS: | 5         | 13       | 1.000000  | 35.607792    | 0.998829          | 0.848739            |\n",
      "PROGRESS: | 6         | 15       | 1.000000  | 43.403919    | 0.999297          | 0.844538            |\n",
      "PROGRESS: | 7         | 16       | 1.000000  | 47.610623    | 0.999297          | 0.844538            |\n",
      "PROGRESS: | 8         | 17       | 1.000000  | 52.056243    | 0.997423          | 0.886555            |\n",
      "PROGRESS: | 9         | 19       | 1.000000  | 58.395830    | 0.999063          | 0.848739            |\n",
      "PROGRESS: | 10        | 20       | 1.000000  | 61.564253    | 0.998595          | 0.848739            |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+-------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "model_stop_tfidf_class = gl.logistic_classifier.create(train_data, target='sponsored', features = ['stop_tfidf','bigrams', 'trigrams','length_html'], class_weights = 'auto')\n",
    "results_class = model_stop_tfidf_class.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8704225352112676, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      0       |        1        |   86  |\n",
       " |      0       |        0        |  859  |\n",
       " |      1       |        0        |   52  |\n",
       " |      1       |        1        |   68  |\n",
       " +--------------+-----------------+-------+\n",
       " [4 rows x 3 columns]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Trying Boosted Decision trees classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_trees = gl.boosted_trees_classifier.create(train_data, target='sponsored', features= ['stop_tfidf','bigrams', 'trigrams','length_html'])\n",
    "#predicitons = model.classify(test_data)\n",
    "results_trees = model_trees.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8985915492957747, 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      0       |        1        |   5   |\n",
       " |      0       |        0        |  940  |\n",
       " |      1       |        0        |  103  |\n",
       " |      1       |        1        |   17  |\n",
       " +--------------+-----------------+-------+\n",
       " [4 rows x 3 columns]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Another parser for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import XMLParser\n",
    "\n",
    "class MaxDepth:                     # The target object of the parser\n",
    "     maxDepth = 0\n",
    "     depth = 0\n",
    "     def start(self, tag, attrib):   # Called for each opening tag.\n",
    "         self.depth += 1\n",
    "         if self.depth > self.maxDepth:\n",
    "             self.maxDepth = self.depth\n",
    "     def end(self, tag):             # Called for each closing tag.\n",
    "         self.depth -= 1\n",
    "     def data(self, data):\n",
    "         pass            # We do not need to do anything with data.\n",
    "     def close(self):    # Called when all data has been parsed.\n",
    "         return self.maxDepth\n",
    "\n",
    "def depth(exampleXml):\n",
    "    target = MaxDepth()\n",
    "    parser = XMLParser(target=target)\n",
    "    parser.feed(exampleXml)\n",
    "    return parser.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
